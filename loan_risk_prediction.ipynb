{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¦ Loan Default Risk Prediction - Financial Risk Analytics\n",
    "\n",
    "This notebook implements a complete machine learning pipeline for predicting loan default risk. It includes data preprocessing, hyperparameter tuning using **GridSearchCV**, and comparative analysis between **Logistic Regression** and **SVM**.\n",
    "\n",
    "### Algorithms & Optimization:\n",
    "- **Logistic Regression**: Regularization tuning (C, penalty).\n",
    "- **SVM**: Kernel comparison (linear, rbf, poly), C, and Gamma tuning.\n",
    "- **Evaluation**: Accuracy, ROC-AUC, Confusion Matrix.\n",
    "- **Cross-Validation**: 5-fold CV for robust results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data\n",
    "Please make sure `train.csv` and `test_Y3wMUE5_7gLdaTN.csv` are uploaded to your Colab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    # Note: Use the specific name provided by the user\n",
    "    test_df = pd.read_csv('test_Y3wMUE5_7gLdaTN.csv')\n",
    "    print(\"âœ… Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Files not found. Please upload 'train.csv' and 'test_Y3wMUE5_7gLdaTN.csv' using the Files tab on the left.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning & Preprocessing\n",
    "We fill missing values (Mode for categorical, Median for numerical) and encode categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, is_train=True):\n",
    "    df_copy = df.copy()\n",
    "    if 'Loan_ID' in df_copy.columns: df_copy.drop('Loan_ID', axis=1, inplace=True)\n",
    "    \n",
    "    cat_cols = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
    "    for col in cat_cols: \n",
    "        if col in df_copy.columns: df_copy[col].fillna(df_copy[col].mode()[0], inplace=True)\n",
    "            \n",
    "    num_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "    for col in num_cols: \n",
    "        if col in df_copy.columns: df_copy[col].fillna(df_copy[col].median(), inplace=True)\n",
    "    \n",
    "    mapping = {\n",
    "        'Gender': {'Male': 1, 'Female': 0},\n",
    "        'Married': {'Yes': 1, 'No': 0},\n",
    "        'Education': {'Graduate': 1, 'Not Graduate': 0},\n",
    "        'Self_Employed': {'Yes': 1, 'No': 0},\n",
    "        'Property_Area': {'Urban': 2, 'Semiurban': 1, 'Rural': 0},\n",
    "        'Dependents': {'0': 0, '1': 1, '2': 2, '3+': 3},\n",
    "        'Loan_Status': {'Y': 1, 'N': 0}\n",
    "    }\n",
    "    \n",
    "    for col, map_val in mapping.items():\n",
    "        if col in df_copy.columns: df_copy[col] = df_copy[col].map(map_val)\n",
    "    return df_copy\n",
    "\n",
    "train_cleaned = preprocess_data(train_df)\n",
    "test_cleaned = preprocess_data(test_df)\n",
    "\n",
    "X = train_cleaned.drop('Loan_Status', axis=1)\n",
    "y = train_cleaned['Loan_Status']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(test_cleaned) if not test_cleaned.empty else None\n",
    "\n",
    "print(\"âœ… Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression Optimization\n",
    "Tuning for $C$ and penalty using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
    "lr_grid = GridSearchCV(LogisticRegression(random_state=42), lr_param_grid, cv=5, scoring='accuracy')\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "best_lr = lr_grid.best_estimator_\n",
    "print(f\"Best Logistic Regression Params: {lr_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM Optimization\n",
    "Tuning Kernel, $C$, and Gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
    "svm_grid = GridSearchCV(SVC(probability=True, random_state=42), svm_param_grid, cv=5, scoring='accuracy')\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "best_svm = svm_grid.best_estimator_\n",
    "print(f\"Best SVM Params: {svm_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_v, y_v, name):\n",
    "    preds = model.predict(X_v)\n",
    "    acc = accuracy_score(y_v, preds)\n",
    "    auc = roc_auc_score(y_v, model.predict_proba(X_v)[:, 1])\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {acc:.4f} | ROC-AUC: {auc:.4f}\")\n",
    "    return acc, auc\n",
    "\n",
    "lr_res = evaluate(best_lr, X_val_scaled, y_val, \"Logistic Regression\")\n",
    "svm_res = evaluate(best_svm, X_val_scaled, y_val, \"SVM\")\n",
    "\n",
    "# Viz\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.barplot(x=['Logistic Regression', 'SVM'], y=[lr_res[0], svm_res[0]], palette='viridis')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_overall = best_svm if svm_res[0] > lr_res[0] else best_lr\n",
    "if X_test_scaled is not None:\n",
    "    test_preds = best_overall.predict(X_test_scaled)\n",
    "    test_df['Loan_Status_Predicted'] = ['Y' if p == 1 else 'N' for p in test_preds]\n",
    "    test_df.to_csv('loan_predictions_result.csv', index=False)\n",
    "    print(\"âœ… Predicted results saved to 'loan_predictions_result.csv'\")\n",
    "    display(test_df[['Loan_ID', 'Loan_Status_Predicted']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
